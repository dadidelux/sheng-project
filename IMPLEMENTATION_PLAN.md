# DSWD Poverty Analysis Web Dashboard - Comprehensive Implementation Plan

## Executive Summary

This document outlines the complete implementation plan for a web-based analytics and prediction dashboard for the Department of Social Welfare and Development (DSWD) poverty analysis project. The system will analyze household poverty data from the MIMAROPA region (L2_dec_roster.csv) and provide three core functionalities:

1. **Geographic Targeting Analysis** - Measure 4Ps program effectiveness by location
2. **Household Clustering** - Segment households beyond binary poor/non-poor classification
3. **SVM Predictive Analytics** - Predict poverty status with optimized questionnaire

---

## Table of Contents

1. [Project Overview](#project-overview)
2. [Tech Stack](#tech-stack)
3. [Architecture](#architecture)
4. [Data Schema](#data-schema)
5. [Implementation Phases](#implementation-phases)
6. [API Specifications](#api-specifications)
7. [Machine Learning Models](#machine-learning-models)
8. [Frontend Components](#frontend-components)
9. [Docker Infrastructure](#docker-infrastructure)
10. [Testing Strategy](#testing-strategy)
11. [Deployment Guide](#deployment-guide)
12. [Timeline & Milestones](#timeline--milestones)

---

## Project Overview

### Background
The project analyzes poverty data from the MIMAROPA region covering:
- **Provinces**: Palawan, Oriental Mindoro, Occidental Mindoro, Romblon, Marinduque
- **Data Source**: L2_dec_roster.csv (67 columns, ~100k+ households)
- **Target Program**: 4Ps (Pantawid Pamilyang Pilipino Program)

### Business Objectives

#### Objective 1: Comprehensive Targeting Analysis
**Goal**: Identify geographic areas with poor 4Ps targeting effectiveness

**Key Metrics**:
- Coverage Rate = (Poor households receiving 4Ps) / (Total poor households)
- Leakage Rate = (Non-poor recipients) / (Total recipients)
- Targeting Accuracy = (Poor recipients) / (Total recipients)
- Unmet Need = Poor households NOT receiving 4Ps

**Actionable Outputs**:
- "Province X has Y poor households not receiving 4Ps"
- "Municipality Z has 30% leakage - needs reassessment"
- Priority ranking for program expansion
- Geographic heatmaps

#### Objective 2: Household Segmentation
**Goal**: Identify distinct household profiles beyond binary poor/non-poor

**Rationale**: Not all poor households have the same needs. Fixed 4K rate may not be appropriate for all segments.

**Expected Clusters**:
- Ultra-poor: Large families, no assets, poor housing, high 4Ps dependency
- Moderate poor: Some basic assets, adequate housing, mixed program participation
- Near-poor/Vulnerable: Most assets but still at risk, lower program participation
- Non-poor: Full asset ownership, good housing, minimal program need

**Actionable Outputs**:
- Nuanced intervention strategies per cluster
- Asset progression pathways
- Geographic clustering patterns
- Policy recommendations for differentiated support

#### Objective 3: SVM Predictive Analytics
**Goal**: Rapid poverty assessment tool for new households

**Features**:
- Optimized questionnaire (reduce from 67 to ~10-15 key fields)
- Real-time poverty prediction (target: 85-89% accuracy)
- Web-based assessment form
- Prediction storage and CSV export

**Value Proposition**: "With just 10 key questions, predict poverty status with 89% accuracy" (vs 85% with all 67 fields)

---

## Tech Stack

### Backend
- **Framework**: FastAPI (Python 3.11+)
- **Database**: ClickHouse 23.x (columnar OLAP database)
- **ML Libraries**:
  - scikit-learn (SVM, clustering)
  - pandas, numpy (data processing)
  - kmodes (K-Prototypes clustering for mixed data)
- **API Documentation**: OpenAPI/Swagger (auto-generated by FastAPI)
- **Validation**: Pydantic v2

### Frontend
- **Framework**: React 18+ with TypeScript (or Vue 3 as alternative)
- **UI Library**: Material-UI (MUI) or Ant Design
- **Charts**: Recharts or Apache ECharts
- **Maps**: Leaflet.js or Mapbox GL JS
- **State Management**: React Query + Zustand
- **Build Tool**: Vite

### DevOps
- **Containerization**: Docker 24+, Docker Compose v2
- **Reverse Proxy**: Nginx (optional, for production)
- **Environment Management**: .env files
- **Version Control**: Git

### Data Processing
- **ETL**: Python scripts with pandas
- **Data Validation**: Great Expectations (optional)
- **Batch Processing**: ClickHouse materialized views

---

## Architecture

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client Browser                       â”‚
â”‚                      (React Dashboard)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP/REST
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Nginx (Reverse Proxy)                     â”‚
â”‚                   Port 80/443 â†’ Docker                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend     â”‚   â”‚   Backend API    â”‚
â”‚  (Port 3000)   â”‚   â”‚   (Port 8000)    â”‚
â”‚   React/Vite   â”‚   â”‚     FastAPI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ClickHouse    â”‚  â”‚  ML Models      â”‚
            â”‚  (Port 8123)   â”‚  â”‚  (Pickle Files) â”‚
            â”‚   Database     â”‚  â”‚  - SVM Model    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  - Clustering   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
sheng_data/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py                  # Configuration settings
â”‚   â”‚   â”œâ”€â”€ database.py                # ClickHouse connection
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py             # Pydantic models
â”‚   â”‚   â”‚   â””â”€â”€ database_models.py     # ClickHouse table schemas
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ targeting.py       # Objective 1 endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ clustering.py      # Objective 2 endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prediction.py      # Objective 3 endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exports.py         # CSV export endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ targeting_service.py   # Business logic for Obj 1
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering_service.py  # Business logic for Obj 2
â”‚   â”‚   â”‚   â””â”€â”€ ml_service.py          # ML predictions
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â”‚   â”œâ”€â”€ svm_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering.py
â”‚   â”‚   â”‚   â””â”€â”€ model_loader.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ helpers.py
â”‚   â”œâ”€â”€ models/                         # Saved ML models
â”‚   â”‚   â”œâ”€â”€ svm_poverty_predictor.pkl
â”‚   â”‚   â”œâ”€â”€ clustering_model.pkl
â”‚   â”‚   â””â”€â”€ feature_selector.pkl
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_targeting.py
â”‚   â”‚   â”œâ”€â”€ test_clustering.py
â”‚   â”‚   â””â”€â”€ test_prediction.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Layout.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TargetingMetrics.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GeographicHeatmap.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ CoverageChart.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LeakageAnalysis.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PriorityRanking.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ClusterProfiles.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AssetDistribution.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ GeographicClusters.tsx
â”‚   â”‚   â”‚   â””â”€â”€ prediction/
â”‚   â”‚   â”‚       â”œâ”€â”€ QuestionnaireForm.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ PredictionResult.tsx
â”‚   â”‚   â”‚       â””â”€â”€ ExportData.tsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalyticsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClusteringPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ PredictionPage.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ init/
â”‚   â”‚   â”œâ”€â”€ 01_create_tables.sql
â”‚   â”‚   â”œâ”€â”€ 02_create_views.sql
â”‚   â”‚   â””â”€â”€ 03_insert_data.sql
â”‚   â””â”€â”€ migrations/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_data.py                 # Enhanced ingestion script
â”‚   â”œâ”€â”€ train_models.py                # ML model training
â”‚   â”œâ”€â”€ feature_selection.py           # Correlation analysis for features
â”‚   â””â”€â”€ setup_database.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ L2_dec_roster.csv
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ IMPLEMENTATION_PLAN.md (this file)
â””â”€â”€ plan.txt (original requirements)
```

---

## Data Schema

### Dataset Overview: L2_dec_roster.csv

**Total Columns**: 67
**Estimated Rows**: ~100,000+ households
**Geographic Coverage**: MIMAROPA Region (5 provinces)

### Key Column Categories

#### 1. Geographic Identifiers (9 columns)
```
- region_name              : REGION IV-B [MIMAROPA]
- province_name            : Palawan, Oriental Mindoro, Occidental Mindoro, Romblon, Marinduque
- city_name                : Municipality/city names
- barangay_name            : Barangay-level location
- psgc_province            : Province code
- psgc_municipality        : Municipality code
- psgc_barangay            : Barangay code
- district                 : District identifier
- urb_rur                  : 1=Urban, 2=Rural
```

#### 2. Target Variables (4 columns)
```
- poverty_status           : "1 - Poor" or "0 - Non Poor"
- poverty_status2          : Binary (0/1)
- poor                     : Binary (0/1)
- received_pppp            : 4Ps program participation (1=Yes, 2=No)
```

#### 3. Household Demographics (5 columns)
```
- no_of_indiv              : Number of individuals
- no_of_families           : Number of families
- no_sleeping_rooms        : Number of sleeping rooms
- l_stay                   : Length of stay (years)
- type_of_household_id     : Household type
```

#### 4. Housing Quality (8 columns)
```
- house_type               : Type of house (1-6 scale)
- roof_mat                 : Roof material (1-6 scale)
- out_wall                 : Outer wall material (1-6 scale)
- tenure_status            : Ownership status
- has_other_property       : Other property ownership
- location_of_property     : Location of other property
- toilet_facilities        : Toilet type (1-8 scale)
- water_supply             : Water source (1-8 scale)
```

#### 5. Utilities & Assets (15 columns)
```
- has_electricity          : 1=Yes, 2=No
- radio                    : 0=No, 1=Yes, 2=Non-functional
- television               : 0/1/2
- video                    : 0/1/2
- stereo                   : 0/1/2
- ref                      : Refrigerator (0/1/2)
- wash_mach                : Washing machine (0/1/2)
- aircon                   : Air conditioner (0/1/2)
- sala_set                 : Living room furniture (0/1/2)
- dining                   : Dining set (0/1/2)
- car_jeep                 : Car/jeep (0-5 scale)
- phone                    : Phone ownership (0-5 scale)
- pc                       : Computer (0/1/2)
- microwave                : Microwave (0/1/2)
- motorcycle               : Motorcycle (0/1/2)
```

#### 6. Program Participation (13 columns)
```
- received_programs        : Any program (1=Yes, 2=No)
- received_scholarship     : Scholarship (1/2)
- received_day_care        : Day care (1/2)
- received_feeding         : Feeding program (1/2)
- received_rice            : Rice subsidy (1/2)
- received_philhealth      : PhilHealth (1/2)
- received_livelihood      : Livelihood assistance (1/2)
- received_housing         : Housing assistance (1/2)
- received_microedit       : Microcredit (1/2)
- received_self_employment : Self-employment (1/2)
- received_pppp            : 4Ps (1/2) *** KEY VARIABLE ***
- received_cash_transfer   : Cash transfer (1/2)
- received_other           : Other programs (1/2)
```

#### 7. Displacement & Other (7 columns)
```
- experienced_displacement : Ever displaced (1/2)
- displacement_manmade     : Man-made disaster (1/2)
- displacement_armed       : Armed conflict (1/2)
- displacement_dev_project : Development project (1/2)
- displacement_other       : Other displacement (1/2)
- is_indigenous            : Indigenous status (1/2)
- indigenous_group         : Indigenous group code
```

#### 8. Administrative (5 columns)
```
- hh_id                    : Unique household ID
- server                   : Server/data source
- respondent               : Respondent type (1/2)
- n_hh                     : Household number
- purok_sitio, street_address, telephone
```

### ClickHouse Table Schema

```sql
CREATE TABLE IF NOT EXISTS poverty_data (
    -- Primary Key
    hh_id String,

    -- Geographic
    region_name String,
    province_name String,
    city_name String,
    barangay_name String,
    psgc_province UInt64,
    psgc_municipality UInt64,
    psgc_barangay UInt64,
    district String,
    urb_rur UInt8,
    purok_sitio String,

    -- Demographics
    no_of_indiv UInt8,
    no_of_families UInt8,
    no_sleeping_rooms UInt8,
    l_stay UInt16,
    type_of_household_id Int16,

    -- Housing
    house_type UInt8,
    roof_mat UInt8,
    out_wall UInt8,
    tenure_status UInt8,
    has_other_property UInt8,
    location_of_property UInt8,
    toilet_facilities UInt8,
    has_electricity UInt8,
    water_supply UInt8,

    -- Assets (0=No, 1=Yes, 2=Non-functional)
    radio UInt8,
    television UInt8,
    video UInt8,
    stereo UInt8,
    ref UInt8,
    wash_mach UInt8,
    aircon UInt8,
    sala_set UInt8,
    dining UInt8,
    car_jeep UInt8,
    phone UInt8,
    pc UInt8,
    microwave UInt8,
    motorcycle UInt8,

    -- Program Participation (1=Yes, 2=No â†’ normalized to 0/1)
    received_programs UInt8,
    received_scholarship UInt8,
    received_day_care UInt8,
    received_feeding UInt8,
    received_rice UInt8,
    received_philhealth UInt8,
    received_livelihood UInt8,
    received_housing UInt8,
    received_microedit UInt8,
    received_self_employment UInt8,
    received_pppp UInt8,          -- KEY: 4Ps participation
    received_cash_transfer UInt8,
    received_other UInt8,

    -- Displacement
    experienced_displacement UInt8,
    displacement_manmade UInt8,
    displacement_armed UInt8,
    displacement_dev_project UInt8,
    displacement_other UInt8,

    -- Indigenous
    is_indigenous UInt8,
    indigenous_group Int16,

    -- Target Variables
    poverty_status String,         -- Original: "1 - Poor" / "0 - Non Poor"
    poverty_status2 UInt8,         -- Binary: 0/1
    poor UInt8,                    -- Binary: 0/1

    -- Other
    respondent UInt8,
    server UInt16,
    telephone String,
    street_address String,
    n_hh UInt8,
    indigenous UInt8,
    archive UInt8

) ENGINE = MergeTree()
ORDER BY (province_name, city_name, barangay_name, hh_id)
PARTITION BY province_name;

-- Create predictions table
CREATE TABLE IF NOT EXISTS poverty_predictions (
    prediction_id UUID DEFAULT generateUUIDv4(),
    prediction_date DateTime DEFAULT now(),

    -- Input features (simplified questionnaire)
    province_name String,
    city_name String,
    urb_rur UInt8,
    no_of_indiv UInt8,
    no_sleeping_rooms UInt8,
    house_type UInt8,
    has_electricity UInt8,
    television UInt8,
    ref UInt8,
    motorcycle UInt8,
    toilet_facilities UInt8,
    water_supply UInt8,
    received_philhealth UInt8,

    -- Prediction output
    predicted_poverty_status UInt8,
    prediction_probability Float32,

    -- Metadata
    model_version String,
    user_session String

) ENGINE = MergeTree()
ORDER BY (prediction_date, prediction_id)
PARTITION BY toYYYYMM(prediction_date);
```

---

## Implementation Phases

### Phase 1: Infrastructure Setup (Week 1)

#### 1.1 Docker Infrastructure
- Create `docker-compose.yml` with 3 services:
  - ClickHouse database
  - FastAPI backend
  - React frontend
- Create Dockerfiles for backend and frontend
- Set up volume mounts and networking
- Configure environment variables

#### 1.2 ClickHouse Database Setup
- Initialize ClickHouse container
- Create database schema (poverty_data table)
- Create predictions table
- Set up materialized views for common aggregations
- Test data ingestion

#### 1.3 Data Ingestion Pipeline
- Enhance existing `ingest_to_clickhouse_fixed.py`
- Add data validation and cleaning
- Handle encoding issues (UTF-8)
- Create data normalization (1/2 â†’ 0/1 for binary fields)
- Log ingestion statistics

**Deliverables**:
- [ ] docker-compose.yml
- [ ] Dockerfile (backend)
- [ ] Dockerfile (frontend)
- [ ] Database schema scripts
- [ ] Enhanced ingestion script
- [ ] README with setup instructions

---

### Phase 2: Backend API Development - Objective 1 (Week 2)

#### 2.1 FastAPI Project Setup
- Initialize FastAPI application structure
- Set up ClickHouse async client
- Configure CORS for frontend
- Implement health check endpoint
- Set up Pydantic models

#### 2.2 Targeting Analysis Endpoints

**Endpoint 1: `/api/v1/targeting/correlation`**
```python
# Calculate correlation between poverty_status2 and received_pppp
# Group by: province, city, barangay
# Returns: correlation coefficient per location

Response Model:
{
  "province_name": "Marinduque",
  "city_name": "Boac",
  "barangay_name": "Agot",
  "correlation": 0.75,
  "total_households": 1250,
  "poor_count": 450,
  "pppp_recipients": 380
}
```

**Endpoint 2: `/api/v1/targeting/coverage`**
```python
# Coverage Analysis
# Coverage Rate = (Poor households with 4Ps) / (Total poor households)

Response Model:
{
  "location": "Marinduque > Boac > Agot",
  "total_poor": 450,
  "poor_with_pppp": 380,
  "coverage_rate": 0.844,  # 84.4%
  "unmet_need": 70,        # Poor households NOT receiving 4Ps
  "program_saturation": 0.32  # Total recipients / Total households
}
```

**Endpoint 3: `/api/v1/targeting/efficiency`**
```python
# Efficiency Metrics

Response Model:
{
  "location": "Marinduque > Boac",
  "total_recipients": 420,
  "poor_recipients": 380,
  "nonpoor_recipients": 40,
  "targeting_accuracy": 0.905,  # 90.5% accuracy
  "leakage_rate": 0.095,        # 9.5% leakage
  "precision": 0.905
}
```

**Endpoint 4: `/api/v1/targeting/priority`**
```python
# Resource Priority Index
# Formula: Priority = (Unmet Need Weight Ã— Unmet Need) +
#                     (Coverage Weight Ã— (1 - Coverage Rate)) +
#                     (Poverty Rate Weight Ã— Poverty Rate)

Response Model:
{
  "rankings": [
    {
      "rank": 1,
      "location": "Palawan > Municipality X",
      "priority_score": 0.87,
      "unmet_need": 1200,
      "coverage_rate": 0.45,
      "poverty_rate": 0.62,
      "recommendation": "High priority for program expansion"
    },
    ...
  ]
}
```

**Endpoint 5: `/api/v1/targeting/heatmap`**
```python
# Geographic heatmap data for visualization

Response Model:
{
  "provinces": [
    {
      "province_name": "Marinduque",
      "metrics": {
        "coverage_rate": 0.82,
        "leakage_rate": 0.12,
        "unmet_need": 2500
      },
      "cities": [
        {
          "city_name": "Boac",
          "metrics": {...},
          "barangays": [...]
        }
      ]
    }
  ]
}
```

#### 2.3 Business Logic Implementation
- Create `targeting_service.py` with calculation functions
- Implement SQL queries for aggregations
- Add caching for frequently accessed data
- Write unit tests

**Deliverables**:
- [ ] FastAPI app structure
- [ ] 5 targeting analysis endpoints
- [ ] Service layer with business logic
- [ ] Unit tests (>80% coverage)
- [ ] API documentation (Swagger)

---

### Phase 3: Backend API Development - Objective 2 (Week 3)

#### 3.1 Clustering Implementation

**ML Approach**: K-Prototypes Clustering
- Handles mixed data types (continuous + categorical)
- Optimal clusters: 4-6 segments
- Features:
  - Continuous: no_of_indiv, l_stay, asset count
  - Categorical: house_type, roof_mat, urb_rur
  - Binary: asset ownership, program participation

#### 3.2 Clustering Endpoints

**Endpoint 1: `/api/v1/clustering/train`**
```python
# Train clustering model
# Method: K-Prototypes or K-Means (asset-based)

Request:
{
  "n_clusters": 5,
  "features": ["no_of_indiv", "house_type", "television", ...],
  "clustering_method": "k-prototypes"
}

Response:
{
  "model_id": "cluster_v1_20250118",
  "n_clusters": 5,
  "silhouette_score": 0.68,
  "training_samples": 98450,
  "cluster_sizes": [15000, 25000, 32000, 18000, 8450]
}
```

**Endpoint 2: `/api/v1/clustering/profiles`**
```python
# Get household cluster profiles

Response Model:
{
  "clusters": [
    {
      "cluster_id": 0,
      "cluster_name": "Ultra-Poor",
      "size": 15000,
      "percentage": 15.2,
      "characteristics": {
        "avg_household_size": 7.2,
        "avg_sleeping_rooms": 1.1,
        "asset_ownership_rate": 0.12,
        "pppp_participation": 0.92,
        "avg_house_quality": 5.8,  # 1=best, 6=worst
        "urban_rate": 0.23
      },
      "top_features": {
        "television": 0.05,
        "ref": 0.02,
        "motorcycle": 0.01
      },
      "poverty_rate": 0.98,
      "description": "Large families with minimal assets, poor housing, high 4Ps dependency"
    },
    {
      "cluster_id": 1,
      "cluster_name": "Moderate Poor",
      ...
    },
    ...
  ]
}
```

**Endpoint 3: `/api/v1/clustering/households/{hh_id}`**
```python
# Get cluster assignment for specific household

Response:
{
  "hh_id": "174001001-2-06393386",
  "cluster_id": 0,
  "cluster_name": "Ultra-Poor",
  "cluster_probability": 0.89,
  "similar_households": 14999
}
```

**Endpoint 4: `/api/v1/clustering/geographic`**
```python
# Geographic clustering - cluster barangays by poverty characteristics

Response Model:
{
  "geographic_clusters": [
    {
      "geo_cluster_id": 0,
      "cluster_name": "High Poverty Urban",
      "locations": [
        "Marinduque > Boac > Agot",
        "Palawan > Puerto Princesa > Barangay X"
      ],
      "characteristics": {
        "avg_poverty_rate": 0.72,
        "avg_pppp_coverage": 0.68,
        "urban_proportion": 0.85,
        "total_households": 12500
      },
      "recommended_intervention": "Urban poverty alleviation programs"
    },
    ...
  ]
}
```

**Endpoint 5: `/api/v1/clustering/insights`**
```python
# Generate actionable insights from clustering

Response:
{
  "insights": [
    {
      "cluster": "Ultra-Poor",
      "insight": "Cluster represents 15.2% of households and needs emergency assistance",
      "recommendation": "Immediate livelihood + housing support",
      "estimated_beneficiaries": 15000,
      "priority": "HIGH"
    },
    {
      "cluster": "Near-Poor/Vulnerable",
      "insight": "27% of households at risk of falling into poverty",
      "recommendation": "Preventive livelihood programs + asset building",
      "estimated_beneficiaries": 26500,
      "priority": "MEDIUM"
    }
  ],
  "asset_progression": {
    "ultra_poor_to_moderate": {
      "key_assets_to_acquire": ["television", "ref", "better_housing"],
      "estimated_cost_per_hh": 15000,
      "timeframe_years": 3
    }
  }
}
```

#### 3.3 ML Service Implementation
- Create `clustering_service.py`
- Implement K-Prototypes algorithm
- Feature engineering for clustering
- Model persistence (save/load)
- Cluster interpretation logic

**Deliverables**:
- [ ] Clustering algorithm implementation
- [ ] 5 clustering endpoints
- [ ] Trained clustering model
- [ ] Cluster profiles and insights
- [ ] Unit tests

---

### Phase 4: Backend API Development - Objective 3 (Week 4)

#### 4.1 Feature Selection via Correlation Analysis

**Objective**: Reduce 67 features to ~10-15 key features while maintaining >85% accuracy

**Method**:
1. Calculate correlation between each feature and poverty_status2
2. Rank features by correlation strength
3. Remove multicollinear features (correlation > 0.8 with each other)
4. Iteratively test feature subsets with SVM
5. Select optimal feature set balancing accuracy and simplicity

**Expected Key Features** (hypothesis):
- Geographic: province_name, urb_rur
- Demographics: no_of_indiv, no_sleeping_rooms
- Housing: house_type, roof_mat, toilet_facilities, water_supply
- Assets: television, ref, motorcycle
- Utilities: has_electricity
- Programs: received_philhealth

#### 4.2 SVM Model Training

**Algorithm**: Support Vector Machine (SVM)
- Kernel: RBF (Radial Basis Function) or Linear
- Hyperparameter tuning: GridSearchCV
- Train/test split: 80/20
- Cross-validation: 5-fold

**Target Performance**:
- Full feature set (67 features): 85% accuracy baseline
- Optimized feature set (~12 features): 89% accuracy target

**Script**: `scripts/train_models.py`
```python
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler

# Load data
X = df[selected_features]
y = df['poverty_status2']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],
    'kernel': ['rbf', 'linear']
}

svm = SVC(probability=True, random_state=42)
grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train_scaled, y_train)

# Evaluate
best_model = grid_search.best_estimator_
accuracy = best_model.score(X_test_scaled, y_test)
print(f"Accuracy: {accuracy:.2%}")

# Save model
import pickle
with open('backend/models/svm_poverty_predictor.pkl', 'wb') as f:
    pickle.dump({
        'model': best_model,
        'scaler': scaler,
        'features': selected_features
    }, f)
```

#### 4.3 Prediction Endpoints

**Endpoint 1: `/api/v1/predict/questionnaire`**
```python
# Get optimized questionnaire fields

Response:
{
  "version": "v1.0",
  "total_fields": 12,
  "estimated_accuracy": 0.89,
  "fields": [
    {
      "field_name": "province_name",
      "label": "Province",
      "type": "select",
      "options": ["Palawan", "Oriental Mindoro", ...],
      "required": true,
      "importance_score": 0.92
    },
    {
      "field_name": "urb_rur",
      "label": "Urban or Rural",
      "type": "radio",
      "options": [{"value": 1, "label": "Urban"}, {"value": 2, "label": "Rural"}],
      "required": true,
      "importance_score": 0.85
    },
    {
      "field_name": "no_of_indiv",
      "label": "Number of household members",
      "type": "number",
      "min": 1,
      "max": 20,
      "required": true,
      "importance_score": 0.78
    },
    ...
  ]
}
```

**Endpoint 2: `/api/v1/predict/poverty`**
```python
# Predict poverty status

Request:
{
  "province_name": "Marinduque",
  "urb_rur": 2,
  "no_of_indiv": 7,
  "no_sleeping_rooms": 1,
  "house_type": 5,
  "has_electricity": 2,
  "television": 0,
  "ref": 0,
  "motorcycle": 0,
  "toilet_facilities": 2,
  "water_supply": 5,
  "received_philhealth": 2
}

Response:
{
  "prediction_id": "uuid-here",
  "predicted_status": 1,              # 1 = Poor
  "predicted_label": "Poor",
  "probability": 0.87,                # 87% confidence
  "probability_poor": 0.87,
  "probability_nonpoor": 0.13,
  "model_version": "svm_v1.0",
  "timestamp": "2025-01-18T10:30:00Z",
  "recommendation": "Eligible for 4Ps program"
}
```

**Endpoint 3: `/api/v1/predict/save`**
```python
# Save prediction to database

Request:
{
  "prediction_id": "uuid-here",
  "input_data": {...},
  "prediction": {...}
}

Response:
{
  "saved": true,
  "prediction_id": "uuid-here",
  "message": "Prediction saved successfully"
}
```

**Endpoint 4: `/api/v1/predict/export`**
```python
# Export predictions as CSV

Query Parameters:
- start_date: 2025-01-01
- end_date: 2025-01-18
- format: csv | json | excel

Response:
- Content-Type: text/csv
- File download: predictions_20250118.csv
```

**Endpoint 5: `/api/v1/predict/statistics`**
```python
# Get prediction statistics

Response:
{
  "total_predictions": 1250,
  "predictions_today": 45,
  "poor_predictions": 580,
  "nonpoor_predictions": 670,
  "avg_confidence": 0.84,
  "model_version": "svm_v1.0",
  "model_accuracy": 0.89,
  "date_range": {
    "start": "2025-01-01",
    "end": "2025-01-18"
  }
}
```

#### 4.4 ML Service Implementation
- Create `ml_service.py`
- Model loader (load trained SVM)
- Prediction pipeline
- Feature preprocessing
- Result formatting

**Deliverables**:
- [ ] Feature selection script
- [ ] SVM training script
- [ ] Trained SVM model (pkl file)
- [ ] 5 prediction endpoints
- [ ] Model evaluation report
- [ ] Unit tests

---

### Phase 5: Frontend Development (Week 5-6)

#### 5.1 Project Setup
- Initialize React + TypeScript + Vite project
- Install dependencies (MUI, Recharts, React Query, etc.)
- Set up routing (React Router)
- Configure API client (Axios)
- Create layout components

#### 5.2 Common Components
- Header with navigation
- Sidebar menu
- Loading states
- Error boundaries
- Toast notifications
- Data export button

#### 5.3 Analytics Dashboard (Objective 1)

**Page**: `/analytics`

**Components**:

1. **TargetingMetrics.tsx**
   - Display coverage rate, leakage rate, targeting accuracy
   - Province/city/barangay selector
   - Metric cards with trend indicators

2. **GeographicHeatmap.tsx**
   - Interactive map (Leaflet)
   - Color-coded by priority score
   - Click to drill down (province â†’ city â†’ barangay)
   - Legend with metric ranges

3. **CoverageChart.tsx**
   - Bar chart: Coverage rate by location
   - Comparison: Target vs Actual
   - Filter by urban/rural

4. **LeakageAnalysis.tsx**
   - Pie chart: Poor vs Non-poor recipients
   - Leakage rate by location (table)
   - Sort by highest leakage

5. **PriorityRanking.tsx**
   - Table: Top 20 priority areas
   - Columns: Rank, Location, Unmet Need, Coverage, Priority Score
   - Export to CSV

**Mockup**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analytics Dashboard                        ğŸ”½ Province     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Coverage  â”‚  â”‚  Leakage  â”‚  â”‚ Targeting â”‚  â”‚  Unmet    â”‚â”‚
â”‚  â”‚   82%     â”‚  â”‚   12%     â”‚  â”‚ Accuracy  â”‚  â”‚   Need    â”‚â”‚
â”‚  â”‚   â–² 5%    â”‚  â”‚   â–¼ 2%    â”‚  â”‚   88%     â”‚  â”‚   2,500   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    â”‚  â”‚  Priority Ranking             â”‚ â”‚
â”‚  â”‚   Geographic       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚   Heatmap          â”‚  â”‚  â”‚ #  â”‚Locationâ”‚Unmet  â”‚Pri â”‚ â”‚ â”‚
â”‚  â”‚   [Interactive     â”‚  â”‚  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤ â”‚ â”‚
â”‚  â”‚    Map]            â”‚  â”‚  â”‚ 1  â”‚Palawan â”‚ 1,200 â”‚0.87â”‚ â”‚ â”‚
â”‚  â”‚                    â”‚  â”‚  â”‚ 2  â”‚Mindoro â”‚   980 â”‚0.82â”‚ â”‚ â”‚
â”‚  â”‚                    â”‚  â”‚  â”‚... â”‚...     â”‚...    â”‚... â”‚ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.4 Clustering Dashboard (Objective 2)

**Page**: `/clustering`

**Components**:

1. **ClusterProfiles.tsx**
   - Cards for each cluster (Ultra-Poor, Moderate Poor, etc.)
   - Cluster characteristics (avg household size, asset ownership, etc.)
   - Poverty rate gauge
   - Recommended interventions

2. **AssetDistribution.tsx**
   - Stacked bar chart: Asset ownership by cluster
   - Assets: TV, Ref, Motorcycle, etc.
   - Asset progression pathway visualization

3. **GeographicClusters.tsx**
   - Map showing geographic clustering
   - Color-coded by cluster type
   - Cluster distribution chart

**Mockup**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Household Clustering                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Ultra-Poor  â”‚ â”‚Moderate Poorâ”‚ â”‚  Near-Poor  â”‚  ...      â”‚
â”‚  â”‚   15,000    â”‚ â”‚   25,000    â”‚ â”‚   32,000    â”‚           â”‚
â”‚  â”‚   (15.2%)   â”‚ â”‚   (25.4%)   â”‚ â”‚   (32.5%)   â”‚           â”‚
â”‚  â”‚             â”‚ â”‚             â”‚ â”‚             â”‚           â”‚
â”‚  â”‚ Poverty: 98%â”‚ â”‚ Poverty: 72%â”‚ â”‚ Poverty: 28%â”‚           â”‚
â”‚  â”‚ Avg HH: 7.2 â”‚ â”‚ Avg HH: 5.5 â”‚ â”‚ Avg HH: 4.8 â”‚           â”‚
â”‚  â”‚ Assets: 12% â”‚ â”‚ Assets: 45% â”‚ â”‚ Assets: 78% â”‚           â”‚
â”‚  â”‚             â”‚ â”‚             â”‚ â”‚             â”‚           â”‚
â”‚  â”‚ â–º Recommend â”‚ â”‚ â–º Recommend â”‚ â”‚ â–º Recommend â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                              â”‚
â”‚  Asset Distribution by Cluster                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ [Stacked Bar Chart]                                   â”‚  â”‚
â”‚  â”‚ Ultra-Poor  â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                           â”‚  â”‚
â”‚  â”‚ Moderate    â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                           â”‚  â”‚
â”‚  â”‚ Near-Poor   â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘                           â”‚  â”‚
â”‚  â”‚ Non-Poor    â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘                           â”‚  â”‚
â”‚  â”‚             TV Ref Motor Wash PC                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.5 Prediction Tool (Objective 3)

**Page**: `/prediction`

**Components**:

1. **QuestionnaireForm.tsx**
   - Dynamic form (12 fields)
   - Field validation
   - Progress indicator
   - Help tooltips

2. **PredictionResult.tsx**
   - Prediction outcome (Poor / Non-Poor)
   - Confidence score (gauge)
   - Recommendation
   - Save/Export buttons

3. **ExportData.tsx**
   - Date range picker
   - Export format selector (CSV/JSON/Excel)
   - Download button
   - Prediction statistics

**Mockup**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Poverty Prediction Tool                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Step 1 of 3: Household Information      [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 40%    â”‚
â”‚                                                              â”‚
â”‚  Province: [â–¼ Select Province    ]                          â”‚
â”‚  Location: ( ) Urban  ( ) Rural                             â”‚
â”‚  Number of household members: [____]                        â”‚
â”‚  Number of sleeping rooms: [____]                           â”‚
â”‚                                                              â”‚
â”‚  [Next â†’]                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  OR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Prediction Result                                  â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚       â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—                     â”‚   â”‚
â”‚  â”‚       â•‘    POOR               â•‘                     â”‚   â”‚
â”‚  â”‚       â•‘    Confidence: 87%    â•‘                     â”‚   â”‚
â”‚  â”‚       â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                     â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  Recommendation: Eligible for 4Ps program           â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  [Save to Database]  [Export as CSV]  [New Predict] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.6 API Integration
- Create API service layer (`services/api.ts`)
- Use React Query for data fetching
- Implement caching and optimistic updates
- Error handling and retry logic

**Deliverables**:
- [ ] React project setup
- [ ] Layout and navigation
- [ ] Analytics dashboard (3 pages)
- [ ] Clustering dashboard (1 page)
- [ ] Prediction tool (1 page)
- [ ] API integration
- [ ] Responsive design (mobile-friendly)

---

## API Specifications

### Base URL
```
http://localhost:8000/api/v1
```

### Authentication
- Currently: None (public API)
- Future: JWT tokens for production

### Common Response Format
```json
{
  "success": true,
  "data": {...},
  "message": "Operation successful",
  "timestamp": "2025-01-18T10:30:00Z"
}
```

### Error Response Format
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input data",
    "details": {...}
  },
  "timestamp": "2025-01-18T10:30:00Z"
}
```

### Pagination (for list endpoints)
```
Query Parameters:
- page: int (default: 1)
- limit: int (default: 50, max: 1000)
- sort_by: string (field name)
- order: "asc" | "desc"

Response:
{
  "data": [...],
  "pagination": {
    "page": 1,
    "limit": 50,
    "total": 1250,
    "total_pages": 25
  }
}
```

### Complete Endpoint List

#### Health Check
- `GET /health` - Health check
- `GET /api/v1/info` - API version and info

#### Objective 1: Targeting Analysis
- `GET /api/v1/targeting/correlation` - Correlation analysis
- `GET /api/v1/targeting/coverage` - Coverage metrics
- `GET /api/v1/targeting/efficiency` - Efficiency metrics
- `GET /api/v1/targeting/priority` - Priority ranking
- `GET /api/v1/targeting/heatmap` - Heatmap data

#### Objective 2: Clustering
- `POST /api/v1/clustering/train` - Train clustering model
- `GET /api/v1/clustering/profiles` - Cluster profiles
- `GET /api/v1/clustering/households/{hh_id}` - Household cluster
- `GET /api/v1/clustering/geographic` - Geographic clusters
- `GET /api/v1/clustering/insights` - Clustering insights

#### Objective 3: Prediction
- `GET /api/v1/predict/questionnaire` - Get questionnaire fields
- `POST /api/v1/predict/poverty` - Predict poverty status
- `POST /api/v1/predict/save` - Save prediction
- `GET /api/v1/predict/export` - Export predictions
- `GET /api/v1/predict/statistics` - Prediction stats

---

## Machine Learning Models

### Model 1: SVM Poverty Predictor

**Purpose**: Predict poverty status (poor/non-poor) from household features

**Algorithm**: Support Vector Machine (SVM)
- **Kernel**: RBF or Linear (to be determined via cross-validation)
- **Input Features**: ~12 selected features (from original 67)
- **Output**: Binary classification (0 = Non-Poor, 1 = Poor) + probability

**Training Process**:
1. Load data: L2_dec_roster.csv
2. Feature selection via correlation analysis
3. Handle missing values (imputation or removal)
4. Encode categorical variables (province_name, etc.)
5. Normalize continuous variables (StandardScaler)
6. Train/test split (80/20)
7. Hyperparameter tuning (GridSearchCV)
8. Cross-validation (5-fold)
9. Evaluate on test set
10. Save model + scaler + feature list

**Performance Metrics**:
- Accuracy: >89% target
- Precision: % of predicted poor that are actually poor
- Recall: % of actual poor that are predicted poor
- F1-Score: Harmonic mean of precision and recall
- Confusion Matrix
- ROC-AUC

**Model Files**:
- `svm_poverty_predictor.pkl` - Trained SVM model
- `feature_scaler.pkl` - StandardScaler for normalization
- `feature_list.json` - List of selected features
- `model_metadata.json` - Training metadata (accuracy, date, etc.)

### Model 2: K-Prototypes Clustering

**Purpose**: Segment households into 4-6 distinct clusters

**Algorithm**: K-Prototypes (from kmodes library)
- Handles mixed data types (continuous + categorical)
- Distance metric: Euclidean (continuous) + Hamming (categorical)

**Features**:
- **Continuous**: no_of_indiv, l_stay, asset_count
- **Categorical**: house_type, roof_mat, out_wall, toilet_facilities, water_supply, urb_rur

**Number of Clusters**: 4-6 (to be determined by elbow method + silhouette score)

**Cluster Interpretation**:
1. Calculate cluster centroids
2. Calculate average values for each feature per cluster
3. Rank clusters by poverty rate
4. Name clusters based on characteristics
5. Generate recommendations per cluster

**Model Files**:
- `clustering_model.pkl` - Trained clustering model
- `cluster_profiles.json` - Cluster characteristics
- `cluster_labels.csv` - Household-to-cluster mapping

---

## Docker Infrastructure

### docker-compose.yml

```yaml
version: '3.8'

services:
  # ClickHouse Database
  clickhouse:
    image: clickhouse/clickhouse-server:23-alpine
    container_name: dswd_clickhouse
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native client
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./database/init:/docker-entrypoint-initdb.d
    environment:
      - CLICKHOUSE_DB=poverty_db
      - CLICKHOUSE_USER=admin
      - CLICKHOUSE_PASSWORD=admin123
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    networks:
      - dswd_network
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: dswd_backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./data:/data
      - ./backend/models:/app/models
    environment:
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=admin
      - CLICKHOUSE_PASSWORD=admin123
      - CLICKHOUSE_DB=poverty_db
      - API_CORS_ORIGINS=http://localhost:3000
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      - dswd_network
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: dswd_frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:8000/api/v1
    depends_on:
      - backend
    networks:
      - dswd_network
    command: npm run dev -- --host 0.0.0.0

volumes:
  clickhouse_data:

networks:
  dswd_network:
    driver: bridge
```

### Backend Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Frontend Dockerfile

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Run development server
CMD ["npm", "run", "dev", "--", "--host", "0.0.0.0"]
```

---

## Testing Strategy

### Backend Testing

#### Unit Tests
- **Framework**: pytest
- **Coverage Target**: >80%
- **Test Files**: `backend/tests/test_*.py`

**Test Categories**:
1. **API Endpoint Tests**
   - Test all endpoints with valid inputs
   - Test error handling (invalid inputs, missing parameters)
   - Test response formats

2. **Service Layer Tests**
   - Test calculation functions (coverage rate, leakage rate, etc.)
   - Test clustering logic
   - Test ML predictions

3. **Database Tests**
   - Test queries return expected results
   - Test data aggregations
   - Test materialized views

**Example Test**:
```python
# backend/tests/test_targeting.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_coverage_endpoint():
    response = client.get("/api/v1/targeting/coverage?province=Marinduque")
    assert response.status_code == 200
    data = response.json()
    assert "coverage_rate" in data["data"]
    assert "unmet_need" in data["data"]
    assert 0 <= data["data"]["coverage_rate"] <= 1
```

#### Integration Tests
- Test end-to-end workflows
- Test database + API integration
- Test ML model loading and prediction

### Frontend Testing

#### Component Tests
- **Framework**: Vitest + React Testing Library
- **Coverage Target**: >70%

**Test Categories**:
1. **Component Rendering**
   - Test components render without errors
   - Test props are displayed correctly

2. **User Interactions**
   - Test form submissions
   - Test button clicks
   - Test filter changes

3. **API Integration**
   - Mock API responses
   - Test loading states
   - Test error states

**Example Test**:
```typescript
// frontend/src/components/prediction/__tests__/QuestionnaireForm.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import QuestionnaireForm from '../QuestionnaireForm';

test('renders questionnaire form', () => {
  render(<QuestionnaireForm />);
  expect(screen.getByLabelText(/Province/i)).toBeInTheDocument();
  expect(screen.getByLabelText(/Number of household members/i)).toBeInTheDocument();
});

test('submits form with valid data', async () => {
  render(<QuestionnaireForm />);

  fireEvent.change(screen.getByLabelText(/Province/i), { target: { value: 'Marinduque' } });
  fireEvent.change(screen.getByLabelText(/Number of household members/i), { target: { value: '5' } });

  fireEvent.click(screen.getByText(/Submit/i));

  // Assert prediction result is displayed
  expect(await screen.findByText(/Prediction Result/i)).toBeInTheDocument();
});
```

### End-to-End Testing

#### Manual Testing Checklist
- [ ] Can access frontend at http://localhost:3000
- [ ] Can access API docs at http://localhost:8000/docs
- [ ] Analytics dashboard loads and displays data
- [ ] Clustering dashboard loads and displays clusters
- [ ] Prediction form accepts input and returns prediction
- [ ] Export CSV functionality works
- [ ] Filters work correctly
- [ ] Maps render correctly
- [ ] Charts render correctly

---

## Deployment Guide

### Prerequisites
- Docker 24+ installed
- Docker Compose v2 installed
- 8GB RAM minimum
- 20GB disk space

### Setup Instructions

#### 1. Clone Repository
```bash
git clone <repository-url>
cd sheng_data
```

#### 2. Environment Configuration
```bash
# Copy example env file
cp .env.example .env

# Edit .env file
# Set CLICKHOUSE_PASSWORD, API_CORS_ORIGINS, etc.
```

#### 3. Prepare Data
```bash
# Ensure data file exists
ls data/L2_dec_roster.csv
```

#### 4. Build and Start Containers
```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# Check status
docker-compose ps
```

#### 5. Initialize Database
```bash
# Run data ingestion script
docker-compose exec backend python /data/ingest_data.py

# Verify data loaded
docker-compose exec clickhouse clickhouse-client --query "SELECT COUNT(*) FROM poverty_db.poverty_data"
```

#### 6. Train ML Models
```bash
# Train SVM model
docker-compose exec backend python scripts/train_models.py

# Train clustering model
docker-compose exec backend python scripts/clustering.py
```

#### 7. Access Application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs
- ClickHouse UI: http://localhost:8123/play

### Troubleshooting

#### Container Issues
```bash
# View logs
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f clickhouse

# Restart services
docker-compose restart

# Rebuild after code changes
docker-compose up -d --build
```

#### Database Issues
```bash
# Access ClickHouse client
docker-compose exec clickhouse clickhouse-client

# Check tables
SHOW TABLES FROM poverty_db;

# Check data
SELECT COUNT(*) FROM poverty_db.poverty_data;
```

#### Backend Issues
```bash
# Check backend health
curl http://localhost:8000/health

# Test API endpoint
curl http://localhost:8000/api/v1/targeting/coverage?province=Marinduque
```

### Production Deployment

#### Additional Considerations
1. **Security**:
   - Change default passwords
   - Use environment variables for secrets
   - Enable HTTPS (add Nginx reverse proxy)
   - Implement authentication (JWT)

2. **Performance**:
   - Increase ClickHouse resources
   - Enable API rate limiting
   - Add Redis for caching
   - Use production builds (React)

3. **Monitoring**:
   - Add logging (ELK stack or similar)
   - Add monitoring (Prometheus + Grafana)
   - Set up alerts

4. **Backup**:
   - Regular database backups
   - Backup ML models
   - Backup configuration files

---

## Timeline & Milestones

### Week 1: Infrastructure Setup
- **Day 1-2**: Docker infrastructure (docker-compose, Dockerfiles)
- **Day 3-4**: ClickHouse schema and data ingestion
- **Day 5**: Testing and documentation

**Deliverables**:
- [ ] Docker environment running
- [ ] Data loaded into ClickHouse
- [ ] Setup documentation

### Week 2: Objective 1 - Targeting Analysis
- **Day 1-2**: FastAPI setup, database connection
- **Day 3-4**: Targeting analysis endpoints (correlation, coverage, efficiency)
- **Day 5**: Priority ranking, heatmap data, testing

**Deliverables**:
- [ ] 5 targeting analysis endpoints
- [ ] API documentation
- [ ] Unit tests

### Week 3: Objective 2 - Clustering
- **Day 1-2**: Clustering algorithm implementation
- **Day 3-4**: Clustering endpoints (profiles, geographic)
- **Day 5**: Insights generation, testing

**Deliverables**:
- [ ] Clustering model trained
- [ ] 5 clustering endpoints
- [ ] Cluster profiles document

### Week 4: Objective 3 - Prediction
- **Day 1-2**: Feature selection, SVM training
- **Day 3-4**: Prediction endpoints (questionnaire, predict, save)
- **Day 5**: Export functionality, testing

**Deliverables**:
- [ ] SVM model trained (>89% accuracy)
- [ ] 5 prediction endpoints
- [ ] Model evaluation report

### Week 5: Frontend - Analytics & Clustering
- **Day 1-2**: React project setup, layout, routing
- **Day 3-4**: Analytics dashboard (targeting metrics, heatmap)
- **Day 5**: Clustering dashboard

**Deliverables**:
- [ ] Frontend project structure
- [ ] Analytics dashboard (2 pages)
- [ ] Clustering dashboard (1 page)

### Week 6: Frontend - Prediction & Integration
- **Day 1-2**: Prediction tool (questionnaire, results)
- **Day 3-4**: API integration, testing
- **Day 5**: Bug fixes, polish, final testing

**Deliverables**:
- [ ] Prediction tool (1 page)
- [ ] Complete frontend-backend integration
- [ ] Responsive design

### Week 7: Testing & Documentation
- **Day 1-2**: Comprehensive testing (unit, integration, E2E)
- **Day 3-4**: User documentation, deployment guide
- **Day 5**: Final review, demo preparation

**Deliverables**:
- [ ] Test reports
- [ ] User manual
- [ ] Deployment guide
- [ ] Demo video

---

## Success Criteria

### Technical Requirements
- [ ] All 3 objectives implemented and functional
- [ ] API endpoints respond within 2 seconds (avg)
- [ ] SVM model achieves >89% accuracy with <15 features
- [ ] Clustering produces 4-6 interpretable clusters
- [ ] Frontend is responsive (mobile-friendly)
- [ ] Docker deployment works on fresh machine
- [ ] Test coverage >80% for backend, >70% for frontend

### Business Requirements
- [ ] System can identify areas with poor 4Ps targeting
- [ ] System provides actionable recommendations (priority areas)
- [ ] System segments households into distinct profiles
- [ ] Prediction tool reduces questionnaire from 67 to ~12 fields
- [ ] Predictions can be exported as CSV
- [ ] Dashboard similar to flood control website (user-friendly)

### Documentation Requirements
- [ ] API documentation (Swagger)
- [ ] User manual with screenshots
- [ ] Deployment guide (step-by-step)
- [ ] Code comments and docstrings
- [ ] README with quick start guide

---

## Future Enhancements

### Phase 2 Features (Post-Launch)
1. **Authentication & Authorization**
   - User login (DSWD staff accounts)
   - Role-based access control (admin, analyst, viewer)
   - Audit logs

2. **Advanced Analytics**
   - Time-series analysis (poverty trends over time)
   - Predictive modeling (forecast future poverty rates)
   - What-if scenarios (simulate program changes)

3. **Data Import/Export**
   - Upload new household data (CSV/Excel)
   - Bulk prediction (upload file, get predictions)
   - Scheduled reports (weekly/monthly)

4. **Mobile Application**
   - Field worker mobile app
   - Offline data collection
   - Sync to cloud database

5. **Integration with DSWD Systems**
   - Connect to Listahanan database
   - Real-time 4Ps beneficiary updates
   - Integration with DSWD reporting tools

6. **Enhanced Visualizations**
   - 3D visualizations
   - Animated charts (time-series)
   - Custom report builder

---

## Appendix

### A. Glossary
- **4Ps**: Pantawid Pamilyang Pilipino Program (conditional cash transfer)
- **DSWD**: Department of Social Welfare and Development
- **MIMAROPA**: Region IV-B (Mindoro, Marinduque, Romblon, Palawan)
- **Coverage Rate**: % of poor households receiving 4Ps
- **Leakage Rate**: % of non-poor households receiving 4Ps
- **Unmet Need**: Poor households NOT receiving 4Ps
- **SVM**: Support Vector Machine (ML algorithm)
- **K-Prototypes**: Clustering algorithm for mixed data types

### B. References
- Original plan: [plan.txt](plan.txt)
- Data source: [data/L2_dec_roster.csv](data/L2_dec_roster.csv)
- DSWD 4Ps Program: https://www.dswd.gov.ph/programs/pantawid-pamilyang-pilipino-program/

### C. Contact & Support
- Project Lead: [Your Name]
- Email: [email@example.com]
- Repository: [GitHub URL]

---

**Document Version**: 1.0
**Last Updated**: January 18, 2025
**Status**: Draft - Ready for Implementation

---

## Quick Start Checklist

To get started implementing this project, follow this checklist:

1. [ ] Review this implementation plan
2. [ ] Set up development environment (Docker, Python, Node.js)
3. [ ] Create project structure (folders as outlined above)
4. [ ] Start with Phase 1: Docker infrastructure
5. [ ] Follow timeline week by week
6. [ ] Test each phase before moving to next
7. [ ] Document as you build
8. [ ] Deploy and celebrate! ğŸ‰

Good luck with the implementation!
